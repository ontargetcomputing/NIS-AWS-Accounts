# How to Import Resources Provisioned via AWS Console

This guide provides instructions for importing AWS resources that were originally provisioned through the AWS Console. 

## Steps for Importing Console-Provisioned Resources

### 1. Identify the Resources to Import

Determine which AWS resources need to be imported. Gather details such as:
- **Resource type** (e.g., VPC, EC2 instance, S3 bucket)
- **AWS Region** where the resource resides
- **Resource identifiers** (e.g., instance IDs, bucket names)

### 2. Open a PR against and Update the Import Log

1. **Open a Pull Request (PR)**:  
   Begin by opening a new pull request against *main* in your repository. 

2. **Update the Import Log**:  
   In the PR, update an [Import Log](./IMPORT_LOG.md) file to document the resources you plan to import. Include:
   - **Resource Type and Name**: Specify the types and names (or identifiers) of resources to be imported (e.g., `VPC - vpc-12345`, `EC2 Instance - i-1234567890abcdef`).
   - **Destination Workspace**: Mention the target Terraform workspace where these resources will be imported.
   - **Region**: Indicate the AWS region of each resource.

   Example entry:
   
   ```markdown
   ## Import Log

   - **Date**: YYYY-MM-DD
   - **Resource**: VPC - `vpc-12345`
   - **Destination Workspace**: `accounts/SBOX-9394/baseline/baseline-workspace`
   - **Region**: us-west-2
   - **Description**: Initial import of the VPC for dev environment.

### 2. Trigger the Import Workflow from the pull request

In the GitHub repository, navigate to **Actions** and manually trigger the [workflow](../../.github/workflows/import.yml) designed for importing resources. When prompted, provide the necessary inputs:

<span style="color: red;">**TODO** - need to allow more resources and filtering</span>

- **Workspace Path**: Select the Terraform workspace path that matches the resource’s environment.
- **Resources**: Choose the resource type(s) you wish to import (e.g., VPC, EC2).
- **AWS Region**: Specify the region where the resource is located.

**Note**: Ensure this workflow is triggered within an open PR. If there is no active PR, the workflow will not execute.

The workflow will perform the follow tasks:

- **Plan the Import with Terraformer**

	The GitHub Action will execute Terraformer to generate a plan for the specified resources. Terraformer scans AWS for the specified resource type and outputs a `plan.json` file, detailing the resource configuration.

- **Run `scripts/cook_plan.py` to Prepare the Plan**

	The `cook_plan.py` script modifies the `plan.json` file to improve resource naming:
	- **Name Tag Check**: It ensures each resource has a `Name` tag. If a resource lacks a `Name` tag, the script will exit, and you’ll need to add a `Name` tag in AWS.
	- **Rename Resources**: For resources with a `Name` tag, the script updates the `ResourceName` to use this tag, providing more meaningful names in Terraform.

### 5. Import Resources into Terraform

The GitHub Action will proceed to import the resources based on the `cooked_plan.json` generated by `cook_plan.py`. The following steps occur automatically:

- **Resource Import**: Each resource in the modified plan is imported into Terraform Cloud.
- **Move Resources to State**: The imported resources are moved to your main Terraform state, allowing Terraform Cloud to manage them.

### 6. Verify and Adjust Resource Attributes

After the import:
1. Run `terraform plan` to compare the imported configuration against the live environment.
2. Check for discrepancies between Terraform attributes and AWS configurations. Update attributes in Terraform as needed to match your desired configuration.

### Example Commands (For Local Testing)

For testing or local import, you can use the following Terraform and Terraformer commands:

- **Terraform Init**: Initializes the Terraform environment.
  ```bash
  terraform init