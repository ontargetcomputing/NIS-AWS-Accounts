# How to Import Resources Provisioned via AWS Console

This guide provides instructions for importing AWS resources that were originally provisioned through the AWS Console. 

## Steps for Importing Console-Provisioned Resources

### 1. Identify and Tag the Resources to Import

1. Determine which AWS resources need to be imported. Gather details such as:
	- **Resource type** (e.g., VPC, EC2 instance, S3 bucket)
	- **AWS Region** where the resource resides
	- **Resource identifiers** (e.g., instance IDs, bucket names)

2. ## Tagging Resources for Import

To selectively import resources using Terraformer, we’ll use the `--filter="Name=tags.<TAG_NAME>"` option. This approach allows you to import only the resources tagged with a specific, unique tag name, ensuring that Terraformer only includes the intended resources in its plan.

### Steps to Tag Resources for Import

1. **Choose a Unique Tag Name**:  
   Select a unique tag key that will be used to identify the resources you want to import. For example, use `IMPORT1`, `IMPORT_DEV`, or `TF_IMPORT_DATE` as the tag key. This key should be distinctive to avoid accidentally including resources not meant for import.

2. **Apply the Tag to Resources**:  
   In the AWS Console, find each resource you want to import and add a tag with the chosen key. For instance, if you chose `IMPORTS_10302024 ` as your tag name, apply this tag to every resource you intend to import.

   - **Tag Key**: Use the unique tag key you chose (e.g., `IMPORTS_10302024`).
   - **Tag Value**: You may leave the value blank or set a descriptive value if preferred.

   Example tag:
   - **Key**: `IMPORTS_10302024 `
   - **Value**: `OptionalDescription`

  This tag will be used to identify specific resources of the chose types to import.


### 2. Open a PR against *main* and Update the Import Log

1. **Open a Pull Request (PR)**:  
   Begin by opening a new pull request against *main* in your repository. 

2. **Update the Import Log**:  
   In the PR, update an [Import Log](./IMPORT_LOG.md) file to document the resources you plan to import. Include:
   - **Date**: Give the current Date
   - **Unique Import Tag**: Give the unique tag name decided above.
   - **Resource Types**: Specify the types of resources to be imported (e.g., `vpc`, `s3`).  See
   - **Destination Workspace**: Mention the target Terraform workspace where these resources will be imported.
   - **Region**: Indicate the AWS region of each resource.
   - **Description**: Give a short description of the work. 

   Example entry:
   
   ```markdown
   ## Import Log

   - **Date**: YYYY-MM-DD
   - **Unique Import Tag**: eg. IMPORTS_10302024
   - **Resource Types**: Specify the types of resources imported
   - **Destination Workspace**: `accounts/SBOX-9394/baseline/baseline-workspace`
   - **Region**: us-west-2
   - **Description**: Initial import of the VPC for dev environment.

### 2. Trigger the Import Workflow from the pull request

In the GitHub repository, navigate to **Actions** and manually trigger the [workflow](../../.github/workflows/import.yml) designed for importing resources. When prompted, provide the necessary inputs:


- **Workspace Path**: Select the Terraform workspace path that matches the resource’s environment.  This is a select list, so choose the appropriate value for the account your are importing from.
- **Resources**: A comma delimited list of the resource types you wish to import.  You can see a list of the available values [here](https://github.com/GoogleCloudPlatform/terraformer/tree/master/providers/aws).
	- **NOTE**: There seems to be a terraformer bug when using '*'. Please do not use.
	- The comma delimited list cannot have spaces in it eg. "vpc,s3" not "vpc, s3"
	 
- **AWS Region**: Specify the region where the resource is located.

**Note**: Ensure this workflow is triggered within an open PR. If there is no active PR, the workflow will not execute.

The workflow will perform the follow tasks:

- **Plan the Import with Terraformer**

	The GitHub Action will execute Terraformer to generate a plan for the specified resources. Terraformer scans AWS for the specified resource type and outputs a `plan.json` file, detailing the resource configuration.

- **Run `scripts/cook_plan.py` to Prepare the Plan**

	The `cook_plan.py` script modifies the `plan.json` file to improve resource naming:
	- **Name Tag Check**: It ensures each resource has a `Name` tag. If a resource lacks a `Name` tag, the script will exit, and you’ll need to add a `Name` tag in AWS.
	- **Rename Resources**: For resources with a `Name` tag, the script updates the `ResourceName` to use this tag, providing more meaningful names in Terraform.

### 5. Import Resources into Terraform

The GitHub Action will proceed to import the resources based on the `cooked_plan.json` generated by `cook_plan.py`. The following steps occur automatically:

- **Resource Import**: Each resource in the modified plan is imported into Terraform Cloud.
- **Move Resources to State**: The imported resources are moved to your main Terraform state, allowing Terraform Cloud to manage them.

### 6. Verify and Adjust Resource Attributes

After the import:

1. Run `terraform plan` to compare the imported configuration against the live environment.
2. Check for discrepancies between Terraform attributes and AWS configurations. Update attributes in Terraform as needed to match your desired configuration.
3. Commit your changes and push to branch.
	1. This will automatically run the plan.
4. Request Review
5. Merge
