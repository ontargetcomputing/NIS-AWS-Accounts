# How to Import Resources Provisioned via AWS Console

This guide provides instructions for importing AWS resources that were originally provisioned through the AWS Console. 

## Steps for Importing Console-Provisioned Resources

### 1. Identify and Tag the Resources to Import

1. Determine which AWS resources need to be imported. Gather details such as:
	- **Resource type** (e.g., VPC, EC2 instance, S3 bucket)
	- **AWS Region** where the resource resides
	- **Resource identifiers** (e.g., instance IDs, bucket names)

2. ## Tagging Resources for Import

To selectively import resources using Terraformer, we’ll use the `--filter="Name=tags.<TAG_NAME>"` option. This approach allows you to import only the resources tagged with a specific, unique tag name, ensuring that Terraformer only includes the intended resources in its plan.

### Steps to Tag Resources for Import

1. **Choose a Unique Tag Name**:  
   Select a unique tag key that will be used to identify the resources you want to import. For example, use `IMPORT1`, `IMPORT_DEV`, or `TF_IMPORT_DATE` as the tag key. This key should be distinctive to avoid accidentally including resources not meant for import.

2. **Apply the Tag to Resources**:  
   In the AWS Console, find each resource you want to import and add a tag with the chosen key. For instance, if you chose `IMPORTS_10302024 ` as your tag name, apply this tag to every resource you intend to import.

   - **Tag Key**: Use the unique tag key you chose (e.g., `IMPORTS_10302024`).
   - **Tag Value**: You may leave the value blank or set a descriptive value if preferred.

   Example tag:
   - **Key**: `IMPORTS_10302024 `
   - **Value**: `OptionalDescription`

  This tag will be used to identify specific resources of the chose types to import.


### 2. Open a PR against and Update the Import Log

1. **Open a Pull Request (PR)**:  
   Begin by opening a new pull request against *main* in your repository. 

2. **Update the Import Log**:  
   In the PR, update an [Import Log](./IMPORT_LOG.md) file to document the resources you plan to import. Include:
   - **Resource Type and Name**: Specify the types and names (or identifiers) of resources to be imported (e.g., `VPC - vpc-12345`, `EC2 Instance - i-1234567890abcdef`).
   - **Destination Workspace**: Mention the target Terraform workspace where these resources will be imported.
   - **Region**: Indicate the AWS region of each resource.

   Example entry:
   
   ```markdown
   ## Import Log

   - **Date**: YYYY-MM-DD
   - **Resource**: VPC - `vpc-12345`
   - **Destination Workspace**: `accounts/SBOX-9394/baseline/baseline-workspace`
   - **Region**: us-west-2
   - **Description**: Initial import of the VPC for dev environment.

### 2. Trigger the Import Workflow from the pull request

In the GitHub repository, navigate to **Actions** and manually trigger the [workflow](../../.github/workflows/import.yml) designed for importing resources. When prompted, provide the necessary inputs:

<span style="color: red;">**TODO** - need to allow more resources and filtering</span>

- **Workspace Path**: Select the Terraform workspace path that matches the resource’s environment.  This is a select list, so choose the appropriate value for the account your are importing from.
- **Resources**: A comma delimited list of the resource types you wish to import.  The default is "*" which attempts to import all resources. You can see a list of the available values [here](https://github.com/GoogleCloudPlatform/terraformer/tree/master/providers/aws).
**NOTE**: This seems to be a terraformer bug when using '*'.  
- **AWS Region**: Specify the region where the resource is located.

**Note**: Ensure this workflow is triggered within an open PR. If there is no active PR, the workflow will not execute.

The workflow will perform the follow tasks:

- **Plan the Import with Terraformer**

	The GitHub Action will execute Terraformer to generate a plan for the specified resources. Terraformer scans AWS for the specified resource type and outputs a `plan.json` file, detailing the resource configuration.

- **Run `scripts/cook_plan.py` to Prepare the Plan**

	The `cook_plan.py` script modifies the `plan.json` file to improve resource naming:
	- **Name Tag Check**: It ensures each resource has a `Name` tag. If a resource lacks a `Name` tag, the script will exit, and you’ll need to add a `Name` tag in AWS.
	- **Rename Resources**: For resources with a `Name` tag, the script updates the `ResourceName` to use this tag, providing more meaningful names in Terraform.

### 5. Import Resources into Terraform

The GitHub Action will proceed to import the resources based on the `cooked_plan.json` generated by `cook_plan.py`. The following steps occur automatically:

- **Resource Import**: Each resource in the modified plan is imported into Terraform Cloud.
- **Move Resources to State**: The imported resources are moved to your main Terraform state, allowing Terraform Cloud to manage them.

### 6. Verify and Adjust Resource Attributes

After the import:
1. Run `terraform plan` to compare the imported configuration against the live environment.
2. Check for discrepancies between Terraform attributes and AWS configurations. Update attributes in Terraform as needed to match your desired configuration.

### Example Commands (For Local Testing)

For testing or local import, you can use the following Terraform and Terraformer commands:

- **Terraform Init**: Initializes the Terraform environment.
  ```bash
  terraform init